{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IDlU-kLCKDVZ"
   },
   "outputs": [],
   "source": [
    "NAME = \"Yin Qiu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kW9zL4V6KDVc"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ECD5r2hFKDVd",
    "nbgrader": {
     "checksum": "9a0ec075584699a44c46933457b0a8ba",
     "grade": false,
     "grade_id": "cell-a910b376742d04c0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Lab 6: Skip Gram\n",
    "\n",
    "**Please read the following instructions very carefully**\n",
    "\n",
    "## Working on the assignment / FAQs\n",
    "- **Always use the seed/random_state as *42* wherever applicable** (This is to ensure repeatability in answers, across students and coding environments) \n",
    "- The type of question and the points they carry are indicated in each question cell\n",
    "- To avoid any ambiguity, each question also specifies what *value* must be set. Note that these are dummy values and not the answers\n",
    "- If an autograded question has multiple answers (due to differences in handling NaNs, zeros etc.), all answers will be considered.\n",
    "- You can delete the `raise NotImplementedError()`\n",
    "- **Submitting the assignment** : Download the '.ipynb' file from Colab and upload it to bcourses. Do not delete any outputs from cells before submitting.\n",
    "- That's about it. Happy coding!\n",
    "\n",
    "\n",
    "Available software:\n",
    " - Python's Gensim module: https://radimrehurek.com/gensim/ (install using pip)\n",
    " - Sklearn’s  TSNE module in case you use TSNE to reduce dimension (optional)\n",
    " - Python’s Matplotlib (optional)\n",
    "\n",
    "_Note: The most important hyper parameters of skip-gram/CBOW are vector size and windows size_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "deletable": false,
    "editable": false,
    "id": "Vsocwry-KDVe",
    "nbgrader": {
     "checksum": "a09a0bf3042da711c4bf843e9b4a4189",
     "grade": false,
     "grade_id": "cell-bf780e597c0216c8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "ee494359-0e5e-4f93-ef51-9fb43acf3c9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
      "--2020-10-27 16:52:58--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.169.29\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.169.29|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1647046227 (1.5G) [application/x-gzip]\n",
      "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
      "\n",
      "GoogleNews-vectors- 100%[===================>]   1.53G  16.5MB/s    in 2m 7s   \n",
      "\n",
      "2020-10-27 16:55:05 (12.4 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!wget -nc https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZF74G9bDKDVh",
    "nbgrader": {
     "checksum": "47031c66b74746d23ccc5e8369446a4b",
     "grade": false,
     "grade_id": "cell-3f89500615a0096f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Q1 (1 point)** \n",
    "Find the cosine similarity between the following word pairs\n",
    "\n",
    "- (France, England)\n",
    "- (smaller, bigger)\n",
    "- (England, London)\n",
    "- (France, Rocket)\n",
    "- (big, bigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AOrCcxCIAGrt"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "zEHazpC_ARBG",
    "outputId": "7a696a62-2781-4f25-d754-497c03030bb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39804944, 0.7302272, 0.43992856, 0.07114174, 0.68423855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "word_pairs = [('France', 'England'),\n",
    "              ('smaller', 'bigger'),\n",
    "              ('England', 'London'),\n",
    "              ('France', 'Rocket'),\n",
    "              ('big', 'bigger')]\n",
    "similarities = []\n",
    "for pair in word_pairs:\n",
    "  similarities.append(model.similarity(pair[0], pair[1]))\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "id": "SZD5ZaMvKDVk",
    "nbgrader": {
     "checksum": "4d52dda406c3d8cd5e37d29755f0fb12",
     "grade": false,
     "grade_id": "cell-fbbe575f8f5a6368",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Replace 0 with the code / value; Do not delete this cell\n",
    "similarity_pair1 = similarities[0]\n",
    "similarity_pair2 = similarities[1]\n",
    "similarity_pair3 = similarities[2]\n",
    "similarity_pair4 = similarities[3]\n",
    "similarity_pair5 = similarities[4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "deletable": false,
    "editable": false,
    "id": "tFUPLSK7KDVp",
    "nbgrader": {
     "checksum": "569aa8b664a41d901bf7b0a5e23e9930",
     "grade": true,
     "grade_id": "cell-929d59ed5d67f618",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "7d323b9e-4327-4269-ef14-142fea45084f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39804944 0.7302272 0.43992856 0.07114174 0.68423855\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit/delete\n",
    "print(similarity_pair1, similarity_pair2, similarity_pair3, similarity_pair4, similarity_pair5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZcqpWCjJKDVs",
    "nbgrader": {
     "checksum": "a7f270405ddf9ecbffde36e6c096b818",
     "grade": false,
     "grade_id": "cell-ccd6618b4fac3715",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Q2 (1 point)** \n",
    "Write an expression to extract the vector representations of the words: \n",
    "\n",
    "- France\n",
    "- England\n",
    "- smaller\n",
    "- bigger\n",
    "- rocket\n",
    "- big\n",
    "\n",
    "Get only the first 5 elements for each vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "v2PuvGIHDFjK",
    "outputId": "56e77dc1-6dae-4d98-8eb1-d95ff3c134b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.04858398, 0.07861328, 0.32421875, 0.03491211, 0.07714844],\n",
      "      dtype=float32), array([-0.19824219,  0.11523438,  0.0625    , -0.05834961,  0.2265625 ],\n",
      "      dtype=float32), array([-0.05004883,  0.03417969, -0.0703125 ,  0.17578125,  0.00689697],\n",
      "      dtype=float32), array([-0.06542969, -0.09521484, -0.06225586,  0.16210938,  0.01989746],\n",
      "      dtype=float32), array([-0.03198242,  0.27148438, -0.2890625 , -0.15429688,  0.16894531],\n",
      "      dtype=float32), array([ 0.11132812,  0.10595703, -0.07373047,  0.18847656,  0.07666016],\n",
      "      dtype=float32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model.wv\n",
    "lst_words = ['France', 'England', 'smaller', 'bigger', 'rocket', 'big']\n",
    "wordrep_5 = []\n",
    "for word in lst_words:\n",
    "  wordrep_5.append(word_vectors[word][:5])\n",
    "print(wordrep_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "id": "6pzKlLyjKDVt",
    "nbgrader": {
     "checksum": "6b3cecb268eb9440c446cd3de984b7f6",
     "grade": false,
     "grade_id": "cell-00f3d05abb28aa23",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Replace 0 with the code / value to get the first 5 elements of each vector; Do not delete this cell\n",
    "vector_1 = wordrep_5[0]\n",
    "vector_2 = wordrep_5[1]\n",
    "vector_3 = wordrep_5[2]\n",
    "vector_4 = wordrep_5[3]\n",
    "vector_5 = wordrep_5[4]\n",
    "vector_6 = wordrep_5[5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "deletable": false,
    "editable": false,
    "id": "Hkj2ROGTKDVv",
    "nbgrader": {
     "checksum": "401940f859774b3c1ec48338fa15682e",
     "grade": true,
     "grade_id": "cell-6f34229370fa873f",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "70316ade-936a-4793-8255-9062bad49e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04858398 0.07861328 0.32421875 0.03491211 0.07714844]\n",
      "[-0.19824219  0.11523438  0.0625     -0.05834961  0.2265625 ]\n",
      "[-0.05004883  0.03417969 -0.0703125   0.17578125  0.00689697]\n",
      "[-0.06542969 -0.09521484 -0.06225586  0.16210938  0.01989746]\n",
      "[-0.03198242  0.27148438 -0.2890625  -0.15429688  0.16894531]\n",
      "[ 0.11132812  0.10595703 -0.07373047  0.18847656  0.07666016]\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit/delete\n",
    "print(vector_1)\n",
    "print(vector_2)\n",
    "print(vector_3)\n",
    "print(vector_4)\n",
    "print(vector_5)\n",
    "print(vector_6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2UBnMwiXKDVy",
    "nbgrader": {
     "checksum": "ac8b42811c924e7988f17b9dbd3f71ef",
     "grade": false,
     "grade_id": "cell-4ad44071d3785409",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Q3 (1 point)** \n",
    "Find the euclidean distances between the word pairs : \n",
    "\n",
    "- (France, England)\n",
    "- (smaller, bigger)\n",
    "- (England, London)\n",
    "- (France, Rocket)\n",
    "- (big, bigger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "3gax7IrOElQJ",
    "outputId": "3f82f139-8fa9-4e4f-ba32-0883221ee5e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0151067, 1.8618743, 2.8752837, 3.892071, 1.9586496]\n"
     ]
    }
   ],
   "source": [
    "def euclidean_dist(pair):\n",
    "  a = pair[0]\n",
    "  b = pair[1]\n",
    "  d = word_vectors[a] - word_vectors[b]\n",
    "  return np.linalg.norm(d)\n",
    "\n",
    "word_pairs = [('France', 'England'),\n",
    "              ('smaller', 'bigger'),\n",
    "              ('England', 'London'),\n",
    "              ('France', 'Rocket'),\n",
    "              ('big', 'bigger')]\n",
    "eu_dists = []\n",
    "for pair in word_pairs:\n",
    "  eu_dists.append(euclidean_dist(pair))\n",
    "\n",
    "print(eu_dists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "id": "zQGd-YVoKDV3",
    "nbgrader": {
     "checksum": "a771483fbb59086604eb84bcc7c7f0ad",
     "grade": false,
     "grade_id": "cell-3aba86afc0ebd8a8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Replace 0 with the code / value; Do not delete this cell\n",
    "eu_dist1 = eu_dists[0]\n",
    "eu_dist2 = eu_dists[1]\n",
    "eu_dist3 = eu_dists[2]\n",
    "eu_dist4 = eu_dists[3]\n",
    "eu_dist5 = eu_dists[4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "deletable": false,
    "editable": false,
    "id": "HsSg0l2UKDV6",
    "nbgrader": {
     "checksum": "17796eb5de342e8f8e841aa137a2c41c",
     "grade": true,
     "grade_id": "cell-15ffa50b82de21ad",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "f1afef97-42c1-48b2-d84a-b6941ec112ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0151067\n",
      "1.8618743\n",
      "2.8752837\n",
      "3.892071\n",
      "1.9586496\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit / delete\n",
    "print(eu_dist1)\n",
    "print(eu_dist2)\n",
    "print(eu_dist3)\n",
    "print(eu_dist4)\n",
    "print(eu_dist5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "XvO2iU7QKDWA",
    "nbgrader": {
     "checksum": "afc0e843c7545e2df83448feda9f28f5",
     "grade": false,
     "grade_id": "cell-7cd8b9b67386376d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Q4 (1 point)**\n",
    "Time to dabble with the power of Word2Vec. Find the 2 closest words  for the following conditions:  \n",
    "- (King - Man + Queen)\n",
    "- (bigger - big + small)\n",
    "- (man + programmer - woman)\n",
    "- (waiting - wait + run)\n",
    "- (Texas + Milwaukee – Wisconsin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "heJg3QDgI-rQ",
    "outputId": "e571eac4-2dda-45f4-ed4c-abe442b0d679"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "def mostsimilar2(positive, negative):\n",
    "  return model.most_similar(positive=positive, negative=negative, topn=2)\n",
    "\n",
    "closest1 = mostsimilar2(['King', 'Queen'], ['Man'])\n",
    "closest2 = mostsimilar2(['bigger', 'small'], ['big'])\n",
    "closest3 = mostsimilar2(['man', 'programmer'], ['woman'])\n",
    "closest4 = mostsimilar2(['waiting', 'run'], ['wait'])\n",
    "closest5 = mostsimilar2(['Texas', 'Milwaukee'], ['Wisconsin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "id": "jCxWmA1eKDWB",
    "nbgrader": {
     "checksum": "50ef096feb166865434fe2fca3d41f99",
     "grade": false,
     "grade_id": "cell-b72201968c5fd1ec",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Replace 0 with the code / value; Do not delete this cell\n",
    "closest1 = closest1\n",
    "closest2 = closest2\n",
    "closest3 = closest3\n",
    "closest4 = closest4\n",
    "closest5 = closest5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "deletable": false,
    "editable": false,
    "id": "io9elfD8KDWE",
    "nbgrader": {
     "checksum": "f9c5ff502264f29d2632c6387f92686a",
     "grade": true,
     "grade_id": "cell-b69718ab0e1470bc",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "86edea1e-e87e-4f7f-d8b7-ddd4cfcf0ca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Queen_Elizabeth', 0.5257916450500488), ('monarch', 0.5004087090492249)]\n",
      "[('larger', 0.7402471899986267), ('smaller', 0.732999324798584)]\n",
      "[('programer', 0.5371963977813721), ('programmers', 0.5310999155044556)]\n",
      "[('running', 0.5654535889625549), ('runs', 0.49640005826950073)]\n",
      "[('Houston', 0.7767744064331055), ('Fort_Worth', 0.7270511388778687)]\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit/delete\n",
    "print(closest1)\n",
    "print(closest2)\n",
    "print(closest3)\n",
    "print(closest4)\n",
    "print(closest5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "erUu4u71KDWJ",
    "nbgrader": {
     "checksum": "6432058d78f4fa52224c48a3b3e71d0d",
     "grade": false,
     "grade_id": "cell-73dca0e2072fef91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Q5 (3 points)**\n",
    "Using the vectors for the words in the Google News dataset, explore the semantic representation of these words through K-means clustering and explain your findings.\n",
    "\n",
    "*Note : Since there are ~3Mil words in the vocabulary, you can downsample it to ~20-30k randomly selected words*\n",
    "\n",
    "**Do not delete the below cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "id": "M3jN02fOKDWK",
    "nbgrader": {
     "checksum": "7ecef46689f11d4d0a6fed72e049235f",
     "grade": true,
     "grade_id": "cell-80b177848b8b0212",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "GlWa0TmaQDY-",
    "outputId": "065ed903-d311-4f1c-9a8a-e2fb76b3aebd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the words to a list, and randomly select 30k of them for clustering\n",
    "keys = word_vectors.index2entity\n",
    "keys = np.random.choice(a=keys, size=30000, replace=False) # randomly select 30000 unique words from the 3 mil words\n",
    "keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "P_gTCdrmVwQY",
    "outputId": "54cbc0d8-d836-42cc-c4b7-6550bd05aac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# use the downsized word vectors to train the kmeans model\n",
    "new_wv = word_vectors[keys]\n",
    "\n",
    "# iterate from 2 to 10 to find best k\n",
    "K = range(2,11)\n",
    "scores = []\n",
    "for k in K:\n",
    "  kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "  kmeans.fit(new_wv)\n",
    "  score = silhouette_score(new_wv, kmeans.labels_) # use silhouette score as metric, higher the better\n",
    "  scores.append(score)\n",
    "\n",
    "max_index = scores.index(max(scores))\n",
    "best_k = max_index+2\n",
    "print(best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "RwMFYmnRWNwG",
    "outputId": "83210d18-6c18-4784-b794-0d8f8e4becc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the kmeans again with the best k of 2\n",
    "kmeans_best = KMeans(n_clusters=best_k, random_state=42)\n",
    "kmeans_best.fit(new_wv)\n",
    "labels = kmeans_best.labels_\n",
    "centers = kmeans_best.cluster_centers_\n",
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "deletable": false,
    "id": "SyOASYXOKDWS",
    "nbgrader": {
     "checksum": "774aef2c5bf8ef9d92e3489d1cd80390",
     "grade": true,
     "grade_id": "cell-90cc4b2c0ae8e2c2",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "f1853ac0-786e-4a55-9c93-c89ad009a7d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21829157"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# silhouette score\n",
    "silhouette_score(new_wv, kmeans_best.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5hmbYuXFTqg"
   },
   "source": [
    "**The silhouette score is supposed to be in -1 to 1. The larger the better. The score for kmeans model when k=2 is only 0.22, which tell us the ratio of intra-cluster distances to inter-cluster distances is about 1/5. It's not very good but still acceptable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "UhHP9W6YdQUt",
    "outputId": "406ef26b-61af-4f93-ef3b-21b803660194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6500, 1: 23500}\n"
     ]
    }
   ],
   "source": [
    "# number of words assigned to each cluster\n",
    "(cluster, counts) = np.unique(kmeans_best.labels_, return_counts=True)\n",
    "print(dict(zip(cluster, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZOd_DSsDwTj"
   },
   "source": [
    "**It appears the majority of words were assigned to cluster 2. For such a big data set and a very small k=2, the imbalanced assignment to cluters may tell us this clustering is not very meaningful. We will check further below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "wFOSB42ueATz",
    "outputId": "415d15e3-3ed2-4bc0-e405-7e44820f591a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Emil_Protalinski_Published', 0.9234708547592163)\n",
      "('By_HuDie_####-##-##', 0.9210418462753296)\n",
      "('BY_GEOFF_KOHL', 0.9189164638519287)\n",
      "('By_QianMian_####-##-##', 0.9186978936195374)\n",
      "('By_XiaoBing_####-##-##', 0.9161226749420166)\n",
      "('BY_DANNY_GALLAGHER', 0.9147441387176514)\n",
      "('STACY_LEE', 0.9140746593475342)\n",
      "('By_Riva_Froymovich', 0.9123396873474121)\n",
      "('REYNOLDS_GALLERY', 0.9099236130714417)\n",
      "('FOOD_OOH_IT', 0.9098910689353943)\n",
      "\n",
      "\n",
      "('http_dol##.net_index###.html_http', 0.914204478263855)\n",
      "('dol##.net_index####.html_http_dol##.net', 0.9038791656494141)\n",
      "('index###.html_http_dol##.net_index###.html', 0.9032235145568848)\n",
      "('Deltagen_undertakes', 0.9029473662376404)\n",
      "('By_TRICIA_SCRUGGS', 0.8984065055847168)\n",
      "('BY_STEFANIE_WHITE', 0.8975433707237244)\n",
      "('Manufacturing_bioplastics', 0.8972487449645996)\n",
      "('PRESCRIPTION_DRUGS_Gradually', 0.8947985768318176)\n",
      "('EXCO_undertakes', 0.8935084342956543)\n",
      "('under_CorMedix_collaborations', 0.8930904865264893)\n"
     ]
    }
   ],
   "source": [
    "# find the 10 most similar words by vector to centroids in cluster 1 and cluster 2\n",
    "close_clu1 = model.similar_by_vector(vector=centers[0], topn=10)\n",
    "close_clu2 = model.similar_by_vector(vector=centers[1], topn=10)\n",
    "\n",
    "# print the 10 similar words in each cluster and respective cosine similarity\n",
    "for word in close_clu1:\n",
    "  print(word)\n",
    "print('\\n')\n",
    "for word in close_clu2:\n",
    "  print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2N_q5rbWMrn"
   },
   "source": [
    "**I found the best k for k-means clustering is 2, using silhouette score. With each of the 2 clusters, I printed the the 10 most similar vectors to the centroid. There is no clear pattern to me in each cluster. I can hypothetically think that the words in the first cluster are relevant to http address and corporate name, and the words in the second cluster are relevant to personal signature and publication series code. However, this is just a hypothesis and needs to be confirmed with further exploration.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "rmdtLoHkKDWR",
    "nbgrader": {
     "checksum": "0467b27a0f59504cbb62b851a002386f",
     "grade": false,
     "grade_id": "cell-5b2a5e8ff6c74323",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Q6 (1 point)**\n",
    "What loss function does the skipgram model use and briefly describe what this function is minimizing.\n",
    "\n",
    "**Do not delete the below cell**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMWPJR8IGaH8"
   },
   "source": [
    "**The loss function for skip-gram algorithm is corss entropy， which is used to measure the negative sum of the predicted probability distribution of the output of softmax. When the output of softmax y_j is close to 1 then log(y_j) in C is close to 0; when y_j is less than 1, -log(y_j) will be larger than 1, making the loss function C larger. We would like to minimize the divergence of predicted probability distribution, so that it will be close to the \"target\" probability distribution (t_j), where the correct class is 1 and everything else is 0. We have t_j times the log(y_j) to keep only the correct class. So minimizing C towards 0 means we have higher predicted probability to the correct output words.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dbpuJx9CKDWV",
    "nbgrader": {
     "checksum": "c14f6069f64cc86ab6e384d28df270d8",
     "grade": false,
     "grade_id": "cell-74a177caaabb5009",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### **Bonus Question (1 point)** \n",
    "Find at least 2 interesting word vec combinations like the ones given in Q4\n",
    "\n",
    "**Do not delete the below cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "deletable": false,
    "id": "pQM8C_T7KDWW",
    "nbgrader": {
     "checksum": "c2d42b5327f4b020c7e1706506dd5ce9",
     "grade": true,
     "grade_id": "cell-7351297993d72e83",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "7423b5dd-9f4f-4a79-f6f4-15c7444d9d1b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sheer_joy', 0.5615313053131104), ('delight', 0.5426716208457947)]\n"
     ]
    }
   ],
   "source": [
    "funwordpair1 = mostsimilar2(['happy','joy'], ['sad'])\n",
    "print(funwordpair1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "X2bPu1AqQPkd",
    "outputId": "3ce706d3-1809-4fdf-ad34-dd5a8f474c4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Southern_California', 0.600623369216919), ('Los_Angeles', 0.5748981237411499)]\n"
     ]
    }
   ],
   "source": [
    "funwordpair2 = mostsimilar2(['California', 'Hollywood'], ['tech'])\n",
    "print(funwordpair2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Qiu_Yin_Lab 6: Skip-grams",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
